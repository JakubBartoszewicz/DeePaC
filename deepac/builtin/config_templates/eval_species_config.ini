[Data]
# Directory containing the data
DataDir = deepac-tests
# Evaluation dataset name: a prefix for input files
DataSet = sample-val
# Paired dataset name: a prefix for input files ("none" for single reads)
PairedSet = none
# Predictions file name. Assumes reads sorted by species and class!
DataPredictions = deepac-test-predictions-sample-val.npy
# Paired predictions file name ("none" for single reads). Assumes reads sorted by species and class!
PairedPredictions = none
# Positive .csv: a .csv file with read numbers per species in the pos. class. Assumes reads sorted by species and class!
PosCSV = img_test_HP_reads.csv
# Negative .csv: a .csv file with read numbers per species in the neg. class. Assumes reads sorted by species and class!
NegCSV = img_test_NP_reads.csv
# CSV delimiter
Delim = ;
# Classification threshold
Threshold = 0.5
# Absolute confidence threshold. Defines an interval d = abs(Threshold - ConfidenceThresh)
# If different than the classification Threshold, predictions in [Threshold - d, Threshold + d] remain unclassified.
ConfidenceThresh = 0.5
# Run name
RunName = deepac-test-species

[Options]
# Draw plots
Do_plots = True
# Ignore reads with no predictions when calculating the performance metrics. Doesn't affect AUC, AUPR and log loss.
Ignore_unmatched = False
